{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d67c017-db51-4aca-906f-84a625d8604b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processando arquivo: RDOD_Mosaic__01.01.2014_16.02.2023_15022023110246 (1).xlsx\n",
      "Identificador encontrado: MOSAIC (Frequência: 2536)\n",
      "Comparação de frequência: Manual (MOSAIC: 2536) vs. Automático (FERTILIZANTES: 2568)\n",
      "Número de linhas no DataFrame combinado: 2509\n",
      "Processando arquivo: RDOD_Raízen__01.01.2014_03.12.2022_02122022160505 (1).xlsx\n",
      "Identificador encontrado: RAIZEN (Frequência: 18586)\n",
      "Número de linhas no DataFrame combinado: 20973\n",
      "Tempo total de execução: 6.86 segundos\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import re\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "def extract_words(column_data):\n",
    "    words_list = []\n",
    "    for row in column_data:\n",
    "        if isinstance(row, str):\n",
    "            words = re.findall(r'\\b\\w{3,}\\b', row)\n",
    "            words_list.extend(words)\n",
    "    return words_list\n",
    "\n",
    "def find_best_identifier(process_df, process_file):\n",
    "    words_list = extract_words(process_df['Réu'])\n",
    "\n",
    "    # Conta a frequência de cada palavra na lista\n",
    "    word_counter = Counter(words_list)\n",
    "    most_common_words = word_counter.most_common()\n",
    "\n",
    "    # Encontra o identificador com base na frequência das palavras\n",
    "    file_words = re.findall(r'\\b\\w{3,}\\b', process_file)\n",
    "\n",
    "    for word, frequency in most_common_words:\n",
    "        if frequency >= len(process_df) * 0.7 and word != \"LTDA\":\n",
    "            return word, frequency\n",
    "\n",
    "    for word in file_words:\n",
    "        if word != \"LTDA\" and word in words_list:\n",
    "            return word, frequency\n",
    "\n",
    "    return \"vazio\", 0\n",
    "\n",
    "# Verifica a frequência de um identificador específico no DataFrame\n",
    "def check_identifier_match(process_df, identifier):\n",
    "    words_list = []\n",
    "\n",
    "    for row in process_df['Réu']:\n",
    "        if isinstance(row, str):\n",
    "            words = re.findall(r'\\b\\w{3,}\\b', row)\n",
    "            words_list.extend(words)\n",
    "\n",
    "    word_counter = Counter(words_list)\n",
    "    identifier_frequency = word_counter[identifier]\n",
    "    return identifier_frequency\n",
    "\n",
    "# Encontra o identificador, levando em conta o manual (se fornecido)\n",
    "def find_identifier(process_df, process_file, manual_identifier=None):\n",
    "    auto_identifier, auto_frequency = find_best_identifier(process_df, process_file)\n",
    "    \n",
    "    if manual_identifier:\n",
    "        manual_frequency = check_identifier_match(process_df, manual_identifier)\n",
    "        if manual_frequency >= len(process_df) * 0.7:\n",
    "            identifier = manual_identifier\n",
    "            frequency = manual_frequency\n",
    "        else:\n",
    "            identifier = auto_identifier\n",
    "            frequency = auto_frequency\n",
    "    else:\n",
    "        identifier = auto_identifier\n",
    "        frequency = auto_frequency\n",
    "\n",
    "    return identifier, frequency\n",
    "\n",
    "process_folder = \"C:\\\\Teste\\\\Monitoramento de processos Kurier\\\\BASE_DE_PROCESSOS_KURIER\"\n",
    "process_files = [f for f in os.listdir(process_folder) if os.path.isfile(os.path.join(process_folder, f))]\n",
    "all_process_dfs = []\n",
    "no_identifier_dfs = []\n",
    "\n",
    "# Obter os nomes das colunas da aba mais à direita da primeira planilha\n",
    "first_file = process_files[0]\n",
    "first_workbook = pd.read_excel(os.path.join(process_folder, first_file), sheet_name=None, header=None)\n",
    "last_sheet_first_workbook = list(first_workbook.values())[-1]\n",
    "column_names = last_sheet_first_workbook.iloc[2].tolist()\n",
    "\n",
    "# Adicione um dicionário para mapear nomes de arquivos a identificadores manuais\n",
    "manual_identifiers = {\n",
    "    \"RDOD_Mosaic__01.01.2014_16.02.2023_15022023110246 (1).xlsx\": \"MOSAIC\"\n",
    "}\n",
    "\n",
    "for process_file in process_files:\n",
    "    print(f\"Processando arquivo: {process_file}\")\n",
    "    workbook = pd.read_excel(os.path.join(process_folder, process_file), sheet_name=None, header=None)\n",
    "    sheet_dfs = []\n",
    "\n",
    "    for sheet_name, sheet in workbook.items():\n",
    "        sheet = sheet.iloc[3:]\n",
    "        sheet.columns = column_names\n",
    "        sheet_dfs.append(sheet)\n",
    "\n",
    "    process_df = pd.concat(sheet_dfs, ignore_index=True)\n",
    "    manual_identifier = manual_identifiers.get(process_file)\n",
    "    identifier, frequency = find_identifier(process_df, process_file, manual_identifier)\n",
    "    print(f\"Identificador encontrado: {identifier} (Frequência: {frequency})\")\n",
    "\n",
    "    if manual_identifier:\n",
    "        auto_identifier, auto_frequency = find_best_identifier(process_df, process_file)\n",
    "        manual_frequency = check_identifier_match(process_df, manual_identifier)\n",
    "        print(f\"Comparação de frequência: Manual ({manual_identifier}: {manual_frequency}) vs. Automático ({auto_identifier}: {auto_frequency})\")\n",
    "\n",
    "    # Separa as linhas que não possuem o identificador e as armazena em um DataFrame separado\n",
    "    no_identifier_rows = process_df[~process_df['Réu'].str.contains(identifier, na=False, case=False)]\n",
    "    no_identifier_dfs.append(no_identifier_rows)\n",
    "\n",
    "    # Remove as linhas que não possuem o identificador do DataFrame principal\n",
    "    process_df = process_df[process_df['Réu'].str.contains(identifier, na=False, case=False)]\n",
    "    process_df['Identificador'] = identifier\n",
    "    all_process_dfs.append(process_df)\n",
    "\n",
    "    combined_df = pd.concat(all_process_dfs, ignore_index=True)\n",
    "    print(\"Número de linhas no DataFrame combinado:\", len(combined_df))\n",
    "\n",
    "    # Combina todos os DataFrames \"Sem_Identificador\" em um único DataFrame\n",
    "    no_identifier_df = pd.concat(no_identifier_dfs, ignore_index=True)\n",
    "    \n",
    "    end_time = time.time()\n",
    "duration = end_time - start_time\n",
    "print(f\"Tempo total de execução: {duration:.2f} segundos\")\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ebbbd924-c28f-4603-be62-89a0e942076b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verificando arquivo: RDOD_Mosaic__01.01.2014_16.02.2023_15022023110246 (1).xlsx\n",
      "Verificando arquivo: RDOD_Raízen__01.01.2014_03.12.2022_02122022160505 (1).xlsx\n",
      "Verificação concluída com sucesso.\n"
     ]
    }
   ],
   "source": [
    "# Verifica se as colunas 'Réu' e 'Identificador' estão presentes no DataFrame combinado\n",
    "if 'Réu' not in combined_df.columns or 'Identificador' not in combined_df.columns:\n",
    "    raise ValueError(\"As colunas 'Réu' e 'Identificador' devem estar presentes no DataFrame combinado.\")\n",
    "\n",
    "# Verifica se não há valores nulos ou vazios nas colunas 'Réu' e 'Identificador' do DataFrame combinado\n",
    "if combined_df['Réu'].isnull().values.any() or combined_df['Réu'].str.strip().eq('').any():\n",
    "    raise ValueError(\"A coluna 'Réu' não pode ter valores nulos ou vazios.\")\n",
    "\n",
    "if combined_df['Identificador'].isnull().values.any() or combined_df['Identificador'].str.strip().eq('').any():\n",
    "    raise ValueError(\"A coluna 'Identificador' não pode ter valores nulos ou vazios.\")\n",
    "    \n",
    "# Verifica se o número de linhas no DataFrame combinado é igual à soma dos números de linhas dos DataFrames individuais\n",
    "if len(combined_df) != sum([len(df) for df in all_process_dfs]):\n",
    "    raise ValueError(\"O número de linhas no DataFrame combinado deve ser igual à soma dos números de linhas dos DataFrames individuais.\")\n",
    "    \n",
    "# Verifica se o número de linhas no DataFrame 'Sem_Identificador' é igual ao número de linhas removidas do DataFrame combinado\n",
    "if len(no_identifier_df) != sum([len(df) for df in no_identifier_dfs]):\n",
    "    raise ValueError(\"O número de linhas no DataFrame 'Sem_Identificador' deve ser igual ao número de linhas removidas do DataFrame combinado.\")\n",
    "    \n",
    "# Verifica se todas as planilhas no arquivo Excel de entrada possuem as mesmas colunas e o mesmo cabeçalho\n",
    "for process_file in process_files:\n",
    "    print(f\"Verificando arquivo: {process_file}\")\n",
    "    workbook = pd.read_excel(os.path.join(process_folder, process_file), sheet_name=None, header=None)\n",
    "    last_sheet_first_workbook = list(workbook.values())[-1]\n",
    "    if last_sheet_first_workbook.iloc[2].tolist() != column_names:\n",
    "        raise ValueError(f\"As planilhas no arquivo '{process_file}' devem ter as mesmas colunas e o mesmo cabeçalho.\")\n",
    "        \n",
    "print(\"Verificação concluída com sucesso.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7d474ac-67a2-4372-ab49-8b5a00a6c210",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Identificador'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3628\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3629\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3630\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Identificador'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_46468\\4046353715.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;31m# Adicionar a coluna \"Origem\" no DataFrame \"no_identifier_df\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m \u001b[0mno_identifier_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Origem\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mno_identifier_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Identificador\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;31m# Exporte todos os DataFrames como abas separadas no arquivo Excel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3503\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3504\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3505\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3506\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3507\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3629\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3630\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3631\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3632\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3633\u001b[0m                 \u001b[1;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Identificador'"
     ]
    }
   ],
   "source": [
    "def find_active_clients(clients_df, identifiers):\n",
    "    active_clients = []\n",
    "    for identifier in identifiers:\n",
    "        clients_with_identifier = clients_df[clients_df['Cliente'].str.contains(identifier, na=False, case=False)].copy()\n",
    "        clients_with_identifier.loc[:, 'Identificador'] = identifier\n",
    "        active_clients.append(clients_with_identifier)\n",
    "    return pd.concat(active_clients, ignore_index=True)\n",
    "\n",
    "# Encontre a planilha mais recente na pasta \"C:\\Teste\\Monitoramento de processos Kurier\\BASE_CLIENTES_ATIVOS_POR_ÁREA_E_TOUCH\"\n",
    "clients_folder = \"C:\\\\Teste\\\\Monitoramento de processos Kurier\\\\BASE_CLIENTES_ATIVOS_POR_ÁREA_E_TOUCH\"\n",
    "client_files = [f for f in os.listdir(clients_folder) if os.path.isfile(os.path.join(clients_folder, f))]\n",
    "client_file = sorted(client_files, key=lambda x: os.path.getmtime(os.path.join(clients_folder, x)))[-1]\n",
    "\n",
    "# Leia a planilha e encontre a coluna \"Cliente\"\n",
    "clients_df = pd.read_excel(os.path.join(clients_folder, client_file))\n",
    "\n",
    "# Encontre os identificadores únicos presentes no DataFrame \"combined_df\"\n",
    "unique_identifiers = combined_df['Identificador'].unique()\n",
    "\n",
    "# Crie um novo DataFrame com os clientes ativos que contêm os identificadores\n",
    "active_clients_df = find_active_clients(clients_df, unique_identifiers)\n",
    "\n",
    "# Exporte todos os DataFrames como abas separadas no arquivo Excel\n",
    "now = datetime.datetime.now().strftime(\"%d.%m.%y_%H.%M\")\n",
    "# Verifique se o arquivo já existe\n",
    "filename = \"C:\\\\Teste\\\\Monitoramento de processos Kurier\\\\BASE_BI\\\\Base_Kurier_Processos_BI.xlsx\"\n",
    "temp_filename = \"C:\\\\Teste\\\\Monitoramento de processos Kurier\\\\BASE_BI\\\\Base_Kurier_Processos_BI_Temp.xlsx\"\n",
    "\n",
    "if os.path.exists(filename):\n",
    "    try:\n",
    "        os.remove(filename)\n",
    "    except PermissionError:\n",
    "        filename = temp_filename\n",
    "else:\n",
    "    filename = filename\n",
    "\n",
    "# Adicionar a coluna \"Origem\" no DataFrame \"no_identifier_df\"\n",
    "no_identifier_df[\"Origem\"] = no_identifier_df[\"Identificador\"]\n",
    "\n",
    "# Exporte todos os DataFrames como abas separadas no arquivo Excel\n",
    "with pd.ExcelWriter(filename) as writer:\n",
    "    combined_df.to_excel(writer, sheet_name=\"Identificados\", index=False)\n",
    "    no_identifier_df.to_excel(writer, sheet_name=\"Sem_Identificador\", index=False)\n",
    "    active_clients_df.to_excel(writer, sheet_name=\"Base_Clientes_Ativos\", index=False)\n",
    "\n",
    "print(f\"Arquivo exportado como: {filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49e53f1-5b7a-4b21-a77c-abc61e637b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar a planilha \"Base_Kurier_Processos_BI.xlsx\" e os DataFrames de clientes e processos\n",
    "clients_df = pd.read_excel(r\"C:\\Teste\\Monitoramento de processos Kurier\\BASE_BI\\Base_Kurier_Processos_BI.xlsx\", sheet_name='Base_Clientes_Ativos')\n",
    "process_df = pd.read_excel(r\"C:\\Teste\\Monitoramento de processos Kurier\\BASE_BI\\Base_Kurier_Processos_BI.xlsx\", sheet_name='Identificados')\n",
    "\n",
    "# Função para remover espaços em branco depois do último dígito de uma string\n",
    "def remove_trailing_spaces(s):\n",
    "    return re.sub(r'\\s+\\Z', '', s)\n",
    "\n",
    "# Função para determinar se um processo é \"Próprio\" (pertence ao cliente) ou não\n",
    "def is_own_process(client_name, cell):\n",
    "    max_char_difference = 3\n",
    "    \n",
    "    # Remover espaços em branco depois do último dígito das strings\n",
    "    client_name = remove_trailing_spaces(client_name)\n",
    "    cell = remove_trailing_spaces(cell)\n",
    "    \n",
    "    # Verificar a diferença no número de caracteres\n",
    "    char_difference = abs(len(client_name) - len(cell))\n",
    "    \n",
    "    if char_difference <= max_char_difference:\n",
    "        # Contar a quantidade de caracteres diferentes entre as strings\n",
    "        char_mismatch_count = sum(1 for a, b in zip(client_name, cell) if a != b)\n",
    "        \n",
    "        if char_mismatch_count <= max_char_difference:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def get_client_name(identifier, clients_df):\n",
    "    client_row = clients_df[clients_df['Cliente'].str.contains(identifier, na=False, case=False)].iloc[0]\n",
    "    return client_row['Cliente']\n",
    "\n",
    "def determine_process_type(row, client_name):\n",
    "    if is_own_process(client_name, row['Réu']):\n",
    "        return \"Próprio\"\n",
    "    else:\n",
    "        return \"Terceiro\"\n",
    "\n",
    "# Processar o DataFrame de processos e adicionar a coluna 'Tipo_Processo'\n",
    "identifier = process_df['Identificador'].iloc[0]\n",
    "client_name = get_client_name(identifier, clients_df)\n",
    "process_df['Tipo_Processo'] = process_df.apply(determine_process_type, axis=1, args=(client_name,))\n",
    "\n",
    "# Salvar as alterações na planilha \"Base_Kurier_Processos_BI.xlsx\"\n",
    "with pd.ExcelWriter(r\"C:\\Teste\\Monitoramento de processos Kurier\\BASE_BI\\Base_Kurier_Processos_BI.xlsx\", mode='a') as writer:\n",
    "    clients_df.to_excel(writer, sheet_name='Base_Clientes_Ativos', index=False)\n",
    "    process_df.to_excel(writer, sheet_name='Identificados', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69151fd5-e450-431e-8eae-3d3174a0dade",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb32ed0a-1165-483a-99e3-6f0678650345",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc-showcode": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
